<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>WriteUp</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h1 id="project-1-finding-lane-lines-on-the-road"><strong>Project 1: Finding Lane Lines on the Road</strong></h1>
<p><strong>Finding Lane Lines on the Road</strong></p>
<p>This project aims to find lane markings on the road  by using computer vision techniques such as Canny Edge detection and Hough Transform line detection.
This project was done as following steps::</p>
<ol>
<li>Color selection/Gray_scaling.</li>
<li>Region of interest selection.</li>
<li>Gaussian smoothing.</li>
<li>Canny Edge detection.</li>
<li>Hough Transform line detection.</li>
<li>Average/extrapolate line segments and draw them onto the image(frame).</li>
<li>Apply to video.</li>
</ol>
<h2 id="reflection">Reflection</h2>
<p><strong><code>draw_line</code></strong> function was modified and replaced with <strong><code>slopebased_draw_lines</code></strong> as followed:<br>
Divide line segments into 2 groups, one with positive slope and another one with negative slope.</p>
<pre><code>if slope &gt; 0:
   positive_slope_lines += [((x1+x2)*0.5,(y1+y2)*0.5, slope)]
else:
   negative_slope_lines += [((x1+x2)*0.5,(y1+y2)*0.5, slope)]
</code></pre>
<p>Then take average <code>slope</code> and <code>x,y</code> value at each group and extrapolate the line segments from the bottom to the top of the region of interest by calculating top and bottom points’s <code>x</code> value.<br></p>
<pre><code>average = [float(sum(l))/len(l) for l in zip(*slope_lines)]
</code></pre>
<pre><code>top_x    = (left_apex[1] - average[1])/average[2]   + average[0]
bottom_x = (left_bottom[1] - average[1])/average[2] + average[0]
</code></pre>
<p>Note: In case of video, the slope and position of left and right line were took average in 20 frames.</p>
<pre><code>aver_negative_slope = average_list(20, global_aver_negative_slope, aver_negative_slope )
aver_positive_slope = average_list(20, global_aver_positive_slope, aver_positive_slope )
</code></pre>
<p>Simple sanity check also be applied to reduce unexpected values at current frames, which exceed 20% values comparing to averaged value.</p>
<pre><code>if (abs(average_l[0]-element[0][0])/average_l[0]) &gt; 0.2 or \
   (abs(average_l[1]-element[0][1])/average_l[1]) &gt; 0.2 :
       l += [(average_l[0],average_l[1])]
       l = l[-l_length:]
</code></pre>

<table>
<thead>
<tr>
<th>Function</th>
<th>Explaination</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>slopebased_draw_lines</code></strong></td>
<td>separate line segments based on its slope value into left and right group, then use <code>extrapolate</code> to each group. To make pipeline more stable, <code>average_list</code> as below was adapted.</td>
</tr>
<tr>
<td><strong><code>extrapolate</code></strong></td>
<td>take average value at each group then extrapolate to top and bottom the region of interest.</td>
</tr>
<tr>
<td><strong><code>average_list</code></strong></td>
<td>take average value over frames (default 20 frames) to make the pipeline more stable. Also, do simple sanity check to filter out any values at current frame exceeded over 20% of averaged values over 20 frames.</td>
</tr>
</tbody>
</table><h3 id="video">Video</h3>
<ol>
<li><a href="https://youtu.be/VCLtHHBUPZA">Video: solidYellowLeft</a></li>
<li><a href="https://youtu.be/tFdcKgX3r5c">Video: solidWhiteRight Video</a></li>
<li><a href="https://youtu.be/RUNxUG4AucU">Videochallenge Video</a></li>
</ol>
<h2 id="discussion">Discussion</h2>
<p><strong>SHORTCOMINGS</strong></p>
<blockquote>
<p><font color="black"> The first shortcoming of this method (Hough Transform) would be relying on the environment conditions. Unclear weather, bad road surface, cars surrounding, other road markings,…etc  may result so much noise at edge detection phase.</font></p>
<ul>
<li>In <strong><code>color selection</code></strong> and <strong><code>region of interest selection</code></strong> section, parameters tuning works well at some specific cases, but it is a challenge to find a common ground of them that could work well in global working environment(for example, lines under shadow/ glaring light or shaped curve ones)</li>
</ul>
</blockquote>
<blockquote>
<p><font color="black"> The another shortcoming  would be straight lane line detection and noises.</font></p>
<ul>
<li><strong><code>extrapolate</code></strong> function which is used for extending averaged line segments from bottom to the top of region of interest would fail in shaped curve. It also easy to fail with noises as mentioned above.</li>
</ul>
</blockquote>
<p><strong>IMPROVEMENTS</strong></p>
<blockquote>
<ul>
<li>Instead of using <strong><code>grayscale</code></strong> function to take gray_scale image, using <strong><code>color_selection</code></strong> (RGB color space )with red and green threshold picked up yellow line better.</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>The purpose of <strong><code>color selection</code></strong> section is to filter out irrelevant pixels of lane lines based on the color. Using different color space rather than RGB may pick up white and yellow pixel more precisely.</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>OpenCV has <strong><code>cv2.polyfit</code></strong> function could draw curved lines. Hough transform’s  output (<code>y value</code>)may be used as input of  <strong><code>cv2.polyfit</code></strong>.</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><strong>Noise</strong> 's solution  would be taking average less few frames or reduce the height of region of interest. Furthermore, I do simple sanity check, which filter out any values exceeded over 20% of averaged values in 20 frames.</li>
</ul>
</blockquote>
</div>
</body>

</html>
